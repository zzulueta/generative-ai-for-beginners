{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting semantic-kernel==0.9.1b1\n",
      "  Downloading semantic_kernel-0.9.1b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting aiofiles<24.0.0,>=23.1.0 (from semantic-kernel==0.9.1b1)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (3.9.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (0.7.1)\n",
      "Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (3.4.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (1.14.3)\n",
      "Collecting openapi_core<0.19.0,>=0.18.0 (from semantic-kernel==0.9.1b1)\n",
      "  Downloading openapi_core-0.18.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (23.6.21.0)\n",
      "Requirement already satisfied: pydantic>2 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (2.6.2)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (1.0.1)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from semantic-kernel==0.9.1b1) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.1b1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.1b1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.1b1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.1b1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.1b1) (1.9.4)\n",
      "Requirement already satisfied: pymongo<5,>=4.5 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==0.9.1b1) (4.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic-kernel==0.9.1b1) (4.9.0)\n",
      "Collecting asgiref<4.0.0,>=3.6.0 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: isodate in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (4.21.1)\n",
      "Collecting jsonschema-spec<0.3.0,>=0.2.3 (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1)\n",
      "  Downloading jsonschema_spec-0.2.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (10.2.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.7.1)\n",
      "Requirement already satisfied: parse in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (1.20.1)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (3.0.1)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (0.18.6)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (2.31.0)\n",
      "Requirement already satisfied: six~=1.15 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>2->semantic-kernel==0.9.1b1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>2->semantic-kernel==0.9.1b1) (2.16.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.1b1) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.1b1) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.1b1) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.1b1) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.31.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.18.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (6.0.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.4.3)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1)\n",
      "  Downloading referencing-0.30.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.1.4)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (0.3.2)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (1.10.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==0.9.1b1) (2.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (2.2.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.1b1) (0.2.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==0.9.1b1) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ziggy\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1) (2.1.5)\n",
      "INFO: pip is looking at multiple versions of jsonschema-specifications to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.19.0,>=0.18.0->semantic-kernel==0.9.1b1)\n",
      "  Downloading jsonschema_specifications-2023.11.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading jsonschema_specifications-2023.11.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading semantic_kernel-0.9.1b1-py3-none-any.whl (246 kB)\n",
      "   ---------------------------------------- 0.0/246.2 kB ? eta -:--:--\n",
      "   --------------------------------- ------ 204.8/246.2 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 246.2/246.2 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading openapi_core-0.18.2-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.4/82.4 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading jsonschema_spec-0.2.4-py3-none-any.whl (14 kB)\n",
      "Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\n",
      "Downloading referencing-0.30.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: referencing, asgiref, aiofiles, jsonschema-specifications, jsonschema-spec, openapi_core, semantic-kernel\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.31.1\n",
      "    Uninstalling referencing-0.31.1:\n",
      "      Successfully uninstalled referencing-0.31.1\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2023.12.1\n",
      "    Uninstalling jsonschema-specifications-2023.12.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2023.12.1\n",
      "  Attempting uninstall: openapi_core\n",
      "    Found existing installation: openapi-core 0.19.0\n",
      "    Uninstalling openapi-core-0.19.0:\n",
      "      Successfully uninstalled openapi-core-0.19.0\n",
      "  Attempting uninstall: semantic-kernel\n",
      "    Found existing installation: semantic-kernel 0.9.4b1\n",
      "    Uninstalling semantic-kernel-0.9.4b1:\n",
      "      Successfully uninstalled semantic-kernel-0.9.4b1\n",
      "Successfully installed aiofiles-23.2.1 asgiref-3.8.1 jsonschema-spec-0.2.4 jsonschema-specifications-2023.7.1 openapi_core-0.18.2 referencing-0.30.2 semantic-kernel-0.9.1b1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install semantic-kernel==0.9.1b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create your environment variables .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your environment variables then run the cell to create the *.env* file with your environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Environment variable obtained from Azure Cosmos DB for MongoDB vCore\n",
    "AZCOSMOS_CONNSTR=os.getenv(\"COSMOS_DB_CONNSTRING\")\n",
    "# Environment variables you set to be used by the code\n",
    "AZCOSMOS_API=\"mongo-vcore\" # currently, semantic kernel only supports vCore\n",
    "AZCOSMOS_DATABASE_NAME=\"database1\"\n",
    "AZCOSMOS_CONTAINER_NAME=\"container1\"\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\") \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "openai.api_embeddings_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "openai.api_version = \"2023-07-01-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the parameters needed by [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) to create the vector search index are handled by semantic kernel.\n",
    "\n",
    "In this guide, we are using `text-embedding-ada-002` embedding model to generate the embeddings which uses a 1536-dimensional embedding vector.\n",
    "\n",
    "The `num_lists` is an integer that represents of clusters that the inverted file (IVF) index uses to group the vector data.\n",
    "\n",
    "The `similarity` used with IVF index here is the `COS` (cosine distance) but you can also try `L2` (Euclidean distance), and `IP` (inner product). For more information see the [Understand embeddings in Azure OpenAI Service article](https://learn.microsoft.com/azure/ai-services/openai/concepts/understand-embeddings#cosine-similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# collection name will be used multiple times in the code so we store it in a variable\n",
    "collection_name = AZCOSMOS_CONTAINER_NAME\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = \"VectorSearchIndex\"\n",
    "vector_dimensions = (\n",
    "    1536  # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    ")\n",
    "num_lists = 1\n",
    "similarity = \"COS\"  # cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a json file of NoSQL records and checks if your data exists in the database using the id of the record then skips the record if it exists or generates embeddings and uploads the database record along with it's embedding.\n",
    "\n",
    "The `save_information` function does two things: generate embeddings + upload the data to your database.\n",
    "\n",
    "Learn more about the semantic kernel memory store [here](https://learn.microsoft.com/semantic-kernel/memories/) and the embeddings [here](https://learn.microsoft.com/semantic-kernel/memories/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
    "\n",
    "\n",
    "async def upsert_data_to_memory_store(\n",
    "    memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes two memory stores and a data file path as arguments.\n",
    "    It is designed to upsert (update or insert) data into the memory stores from the data file.\n",
    "\n",
    "    Args:\n",
    "        kernel_memory_store (callable): A callable object that represents the kernel memory store where data will be upserted.\n",
    "        memory_store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory stores in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n += 1\n",
    "            # check if the item already exists in the memory store\n",
    "            # if the id doesn't exist, it throws an exception\n",
    "            try:\n",
    "                already_created = bool(\n",
    "                    await store.get(\n",
    "                        collection_name, item[\"id\"], with_embedding=True\n",
    "                    )\n",
    "                )\n",
    "            except Exception:\n",
    "                already_created = False\n",
    "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
    "            if not already_created:\n",
    "                await memory.save_information(\n",
    "                    collection=collection_name,\n",
    "                    id=item[\"id\"],\n",
    "                    # the embedding is generated from the text field\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"],\n",
    "                )\n",
    "                print(\n",
    "                    \"Generating embeddings and saving new item:\",\n",
    "                    n,\n",
    "                    \"/\",\n",
    "                    len(data),\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add the Chat and Embedding models to the Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the semantic kernel, and initialize the semantic kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "\n",
    "# Intialize the kernel\n",
    "kernel = sk.Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries.\n",
    "\n",
    "We need the chat completion for having a conversation and text embeddings for generating embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the chat deployment name, initialize the chat completions with the required parameters, and add the created chat service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Chat Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai chat service\n",
    "chat_model_deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"chat_completion\",\n",
    "        deployment_name=chat_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Chat Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings deployment name and initialize the text embedding with the required parameters, and add the created embedding service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Embedding Generation Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai text embedding service\n",
    "embedding_model_deployment_name = os.environ.get(\n",
    "    \"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"\n",
    ")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureTextEmbedding(\n",
    "        service_id=\"text_embedding\",\n",
    "        deployment_name=embedding_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create or Update Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic kernel can handel the database, collection, index creation.\n",
    "\n",
    "Import the Azure CosmosDB memory store and initialize it with the parameters defined before.\n",
    "\n",
    "If the database, collection, and index exist it won't overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating Azure Cosmos DB Memory Store...\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "The resolution lifetime expired after 20.008 seconds: Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating or updating Azure Cosmos DB Memory Store...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# create azure cosmos db for mongo db vcore api store and collection with vector ivf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# currently, semantic kernel only supports the ivf vector kind\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m AzureCosmosDBMemoryStore\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      9\u001b[0m     cosmos_connstr\u001b[38;5;241m=\u001b[39mAZCOSMOS_CONNSTR,\n\u001b[0;32m     10\u001b[0m     cosmos_api\u001b[38;5;241m=\u001b[39mAZCOSMOS_API,\n\u001b[0;32m     11\u001b[0m     database_name\u001b[38;5;241m=\u001b[39mAZCOSMOS_DATABASE_NAME,\n\u001b[0;32m     12\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mAZCOSMOS_CONTAINER_NAME,\n\u001b[0;32m     13\u001b[0m     index_name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[0;32m     14\u001b[0m     vector_dimensions\u001b[38;5;241m=\u001b[39mvector_dimensions,\n\u001b[0;32m     15\u001b[0m     num_lists\u001b[38;5;241m=\u001b[39mnum_lists,\n\u001b[0;32m     16\u001b[0m     similarity\u001b[38;5;241m=\u001b[39msimilarity,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished updating Azure Cosmos DB Memory Store...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\memory\\azure_cosmosdb\\azure_cosmos_db_memory_store.py:68\u001b[0m, in \u001b[0;36mAzureCosmosDBMemoryStore.create\u001b[1;34m(cosmos_connstr, cosmos_api, database_name, collection_name, index_name, vector_dimensions, num_lists, similarity)\u001b[0m\n\u001b[0;32m     66\u001b[0m apiStore: AzureCosmosDBStoreApi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cosmos_api \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongo-vcore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 68\u001b[0m     mongodb_client \u001b[38;5;241m=\u001b[39m \u001b[43mget_mongodb_search_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosmos_connstr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m     database \u001b[38;5;241m=\u001b[39m mongodb_client[database_name]\n\u001b[0;32m     70\u001b[0m     apiStore \u001b[38;5;241m=\u001b[39m MongoStoreApi(\n\u001b[0;32m     71\u001b[0m         collection_name,\n\u001b[0;32m     72\u001b[0m         index_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         database,\n\u001b[0;32m     77\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\semantic_kernel\\connectors\\memory\\azure_cosmosdb\\cosmosdb_utils.py:32\u001b[0m, in \u001b[0;36mget_mongodb_search_client\u001b[1;34m(connection_string)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: missing Azure Cosmos Mongo vCore Connection String\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cosmos_conn_str:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMongoClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcosmos_conn_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: unable to create Azure Cosmos Mongo vCore Vector DB client.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pymongo\\mongo_client.py:771\u001b[0m, in \u001b[0;36mMongoClient.__init__\u001b[1;34m(self, host, port, document_class, tz_aware, connect, type_registry, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mvalidate_timeout_or_none_or_zero(\n\u001b[0;32m    769\u001b[0m         keyword_opts\u001b[38;5;241m.\u001b[39mcased_key(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnecttimeoutms\u001b[39m\u001b[38;5;124m\"\u001b[39m), timeout\n\u001b[0;32m    770\u001b[0m     )\n\u001b[1;32m--> 771\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43muri_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrv_service_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrv_service_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrv_max_hosts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrv_max_hosts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m seeds\u001b[38;5;241m.\u001b[39mupdate(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodelist\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    782\u001b[0m username \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m username\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pymongo\\uri_parser.py:559\u001b[0m, in \u001b[0;36mparse_uri\u001b[1;34m(uri, default_port, validate, warn, normalize, connect_timeout, srv_service_name, srv_max_hosts)\u001b[0m\n\u001b[0;32m    557\u001b[0m dns_resolver \u001b[38;5;241m=\u001b[39m _SrvResolver(fqdn, connect_timeout, srv_service_name, srv_max_hosts)\n\u001b[0;32m    558\u001b[0m nodes \u001b[38;5;241m=\u001b[39m dns_resolver\u001b[38;5;241m.\u001b[39mget_hosts()\n\u001b[1;32m--> 559\u001b[0m dns_options \u001b[38;5;241m=\u001b[39m \u001b[43mdns_resolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dns_options:\n\u001b[0;32m    561\u001b[0m     parsed_dns_options \u001b[38;5;241m=\u001b[39m split_options(dns_options, validate, warn, normalize)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pymongo\\srv_resolver.py:90\u001b[0m, in \u001b[0;36m_SrvResolver.get_options\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;28mstr\u001b[39m(exc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one TXT record is supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mConfigurationError\u001b[0m: The resolution lifetime expired after 20.008 seconds: Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out.; Server Do53:10.16.3.143@53 answered The DNS operation timed out.; Server Do53:192.168.1.1@53 answered The DNS operation timed out.; Server Do53:10.32.1.7@53 answered The DNS operation timed out."
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store = await AzureCosmosDBMemoryStore.create(\n",
    "    cosmos_connstr=AZCOSMOS_CONNSTR,\n",
    "    cosmos_api=AZCOSMOS_API,\n",
    "    database_name=AZCOSMOS_DATABASE_NAME,\n",
    "    collection_name=AZCOSMOS_CONTAINER_NAME,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity,\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the created memory store to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
    "kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate embeddings and Create Database records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the helper function with the JSON data file to generate embeddings and create or update the database records.\n",
    "\n",
    "If the records already exit it will skip it.\n",
    "\n",
    "Records are identified by their ids.\n",
    "\n",
    "The data used here is a dummy data which you can replace with your own.\n",
    "\n",
    "**Note that you need to specify id, text, and description fields.\n",
    "The text field is what gets converted to embeddings.**\n",
    "\n",
    "See the helper function definition for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Skipping item already exits: 107 / 107\r"
     ]
    }
   ],
   "source": [
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(memory, store, \"./src/data/text-sample.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search function converts the query_term to a vector embedding and finds the similarity between it and the database records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What is Azure Database for Managed Instances?\"\n",
    "result = await memory.search(collection_name, query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\n",
      "Relevance Score: 0.8967287909762478\n",
      "Full Record: {\"text\": \"Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\", \"description\": \"Azure SQL Managed Instance\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create chat function with Azure OpenAI chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "\n",
    "execution_settings = sk_oai.OpenAITextPromptExecutionSettings(\n",
    "   service_id=\"chat_completion\",\n",
    "    ai_model_id=chat_model_deployment_name,\n",
    "    max_tokens=500,\n",
    "    temperature=0.0,\n",
    "    top_p=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "chat_prompt_template_config = sk.PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"grounded_response\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.create_function_from_prompt(\n",
    "    prompt=prompt,\n",
    " function_name= \"ChatGPTFunc2\", plugin_name=\"chatGPTPlugin2\", prompt_template_config=chat_prompt_template_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_result = await kernel.invoke(chat_function, sk.KernelArguments(query_term=query_term, db_record=result[0].additional_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure SQL Managed Instance is a fully managed, scalable, and secure SQL Server instance hosted in Azure. It provides features like automatic backups, monitoring, and high availability. SQL Managed Instance supports various data types, such as JSON, spatial, and full-text. You can use Azure SQL Managed Instance to migrate your existing applications, build new applications, and ensure the performance and security of your data. It also integrates with other Azure services, such as Azure App Service and Azure Data Factory.\n"
     ]
    }
   ],
   "source": [
    "print(completions_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Testing the RAG flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Hey\n",
      "Response:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "Question:\n",
      "What is the best place to host my website on Azure?\n",
      "Response:\n",
      "Azure App Service is a great option for hosting your website on Azure. It is a fully managed platform that supports a variety of programming languages and frameworks. It also offers built-in auto-scaling and load balancing capabilities, making it easy to scale your website as needed. Additionally, it provides integration with other Azure services, such as Azure DevOps, GitHub, and Bitbucket.\n",
      "\n",
      "Question:\n",
      "What is the easiest database to use on Azure?\n",
      "Response:\n",
      "Azure SQL Database is the easiest database to use on Azure.\n",
      "\n",
      "Question:\n",
      "exit\n",
      "Response:\n",
      "Goodbye! Have a great day!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    result = await memory.search(collection_name, query_term)\n",
    "    completions_result = kernel.invoke_stream(chat_function, sk.KernelArguments(query_term=query_term, db_record=result[0].additional_metadata))\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    async for completion in completions_result:\n",
    "        print(str(completion[0]), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
