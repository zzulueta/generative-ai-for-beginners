{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-identity\n",
    "%pip install azure-search-documents\n",
    "%pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import openai\n",
    "import os\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Initialize Azure search variables\n",
    "AZURE_AI_SEARCH_ENDPOINT = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "AZURE_AI_SEARCH_API_KEY = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "AZURE_AI_SEARCH_INDEX = os.getenv(\"AZURE_AI_SEARCH_INDEX\")\n",
    "AZURE_AI_SEARCH_RESULTS = os.getenv(\"AZURE_AI_SEARCH_RESULTS\")\n",
    "AZURE_AI_SEARCH_SEMANTIC = str(os.getenv(\"AZURE_AI_SEARCH_SEMANTIC\"))    \n",
    "AZURE_AI_SEARCH_CONTENT = os.getenv(\"AZURE_AI_SEARCH_CONTENT\")\n",
    "AZURE_AI_SEARCH_FILEPATH = os.getenv(\"AZURE_AI_SEARCH_FILEPATH\")\n",
    "AZURE_AI_SEARCH_VECTOR = os.getenv(\"AZURE_AI_SEARCH_VECTOR\")\n",
    "\n",
    "# Set up OpenAI client based on environment variables\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "AZURE_OPENAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_MAX_RESPONSE = int(os.getenv(\"AZURE_OPENAI_MAX_RESPONSE\"))\n",
    "\n",
    "azure_credential = AzureKeyCredential(AZURE_AI_SEARCH_API_KEY)\n",
    "\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_KEY,)\n",
    "\n",
    "# get the embedding of a text\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# save chat history to azure Cosmos DB mongodb collection\n",
    "def save_chat_history(input, content, output):\n",
    "    \n",
    "    # Cosmos DB settings\n",
    "    connection_string = os.getenv(\"AZCOSMOS_CONNSTR\")\n",
    "    client = MongoClient(connection_string)\n",
    "    databasename = os.getenv(\"AZCOSMOS_CHAT_DATABASE_NAME\")\n",
    "    collectionname = os.getenv(\"AZCOSMOS_CHAT_CONTAINER_NAME\")\n",
    "    db = client[databasename]\n",
    "    collection = db[collectionname]\n",
    "\n",
    "    # Get the current timestamp in UTC+8\n",
    "    utc_8 = pytz.timezone(\"Asia/Singapore\")\n",
    "    timestamp = datetime.now(utc_8).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Define the record to insert\n",
    "    record = {\n",
    "        \"input\": input,\n",
    "        \"content\": content,\n",
    "        \"output\": output,\n",
    "        \"type\": \"pdf_chat\",\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "    # Insert the record into the collection\n",
    "    collection.insert_one(record)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2292/1657996152.py:47: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  client = MongoClient(connection_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: A Public Key Infrastructure (PKI) is essentially a set of hardware, software, policies, personnel, and procedures needed to create, manage, distribute, use, store, and revoke digital certificates. It is encapsulated in the Department of Information and Communications Technology's (DICT) Philippine National Public Key Infrastructure (PNPKI) services, which include Certificate Authority & Registration Authority, Validation Authority, and Timestamping services [CIRCULAR-LETTER-NO-2024-7-DATED-FEBRUARY-27-2024.pdf].\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(AZURE_AI_SEARCH_ENDPOINT, AZURE_AI_SEARCH_INDEX, credential=azure_credential)\n",
    "\n",
    "input = \"What is a Public Key Infrastructure?\"\n",
    "search_vector = get_embedding(input)\n",
    "\n",
    "r = search_client.search(\n",
    "        input,\n",
    "        top=AZURE_AI_SEARCH_RESULTS, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=search_vector, k_nearest_neighbors=50, fields=AZURE_AI_SEARCH_VECTOR)],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=AZURE_AI_SEARCH_SEMANTIC)\n",
    "\n",
    "# Initialize an empty list to accumulate all content and sources\n",
    "all_content_list = []\n",
    "\n",
    "# Iterate over the search results\n",
    "for doc in r:\n",
    "    content = doc[AZURE_AI_SEARCH_CONTENT].replace(\"\\n\", \" \")\n",
    "    source = doc[AZURE_AI_SEARCH_FILEPATH]\n",
    "    combined_content = f\"Content: {content} Source: {source}\"\n",
    "    all_content_list.append(combined_content)  # Append combined content and source to the list\n",
    "    \n",
    "# Join the list into a single string with a space separator\n",
    "all_content = \" \".join(all_content_list)\n",
    "\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"Assistant helps user questions about the circulars. \n",
    "    Answer only with the facts listed in the sources provided.\n",
    "    If there isn't enough information provided, say you don't know.\n",
    "    Each source has a Content followed by a colon which contains the actual information including the source name for each fact you use.\n",
    "    Use square brackets to reference the source, for example [info1.txt]\"\"\"\n",
    "\n",
    "USER_MESSAGE = input + \"\\nSources:\" + all_content\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_DEPLOYMENT,\n",
    "    temperature=0.0,\n",
    "    max_tokens=AZURE_OPENAI_MAX_RESPONSE,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    "    top_p=0.5\n",
    ")\n",
    "\n",
    "save_chat_history(input, all_content, response.choices[0].message.content)\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(AZURE_AI_SEARCH_ENDPOINT, AZURE_AI_SEARCH_INDEX, credential=azure_credential)\n",
    "\n",
    "search_query = \"I have a worker who helped me in my project and I want to pay him token for the service he provided as a thank you. how much can i give him?\"\n",
    "search_vector = get_embedding(search_query)\n",
    "\n",
    "r = search_client.search(\n",
    "        search_query,\n",
    "        top=AZURE_AI_SEARCH_RESULTS, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=search_vector, k_nearest_neighbors=50, fields=\"contentVector\")],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"azureml-default\")\n",
    "\n",
    "# Initialize an empty list to accumulate all content and sources\n",
    "all_content_list = []\n",
    "\n",
    "# Iterate over the search results\n",
    "for doc in r:\n",
    "    content = doc[\"content\"].replace(\"\\n\", \" \")\n",
    "    source = doc[\"filepath\"]\n",
    "    combined_content = f\"Content: {content} Source: {source}\"\n",
    "    all_content_list.append(combined_content)  # Append combined content and source to the list\n",
    "    \n",
    "# Join the list into a single string with a space separator\n",
    "all_content = \" \".join(all_content_list)\n",
    "\n",
    "#print all_content into a txt file\n",
    "with open(\"all_content.txt\", \"w\") as file:\n",
    "    \n",
    "    file.write(all_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
