{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Environment variable obtained for Azure Cosmos DB for MongoDB vCore\n",
    "AZCOSMOS_CONNSTR=os.getenv(\"AZCOSMOS_CONNSTR\")\n",
    "AZCOSMOS_API=os.getenv(\"AZCOSMOS_API\")\n",
    "AZCOSMOS_DATABASE_NAME=\"dbm\"\n",
    "AZCOSMOS_CONTAINER_NAME=\"dbm_saro\"\n",
    "\n",
    "# Envrionment variables obtained for Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\") \n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "openai.api_embeddings_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "\n",
    "# collection name will be used multiple times in the code so we store it in a variable\n",
    "collection_name = AZCOSMOS_CONTAINER_NAME\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = \"VectorSearchIndex\"\n",
    "vector_dimensions = (\n",
    "    1536  # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    ")\n",
    "num_lists = 1\n",
    "similarity = \"COS\"  # cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Helper Function\n",
    "\n",
    "This function takes in a json file of NoSQL records and checks if your data exists in the database using the id of the record then skips the record if it exists or generates embeddings and uploads the database record along with it's embedding.\n",
    "\n",
    "The `save_information` function does two things: generate embeddings + upload the data to your database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
    "\n",
    "\n",
    "async def upsert_data_to_memory_store(\n",
    "    memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes two memory stores and a data file path as arguments.\n",
    "    It is designed to upsert (update or insert) data into the memory stores from the data file.\n",
    "\n",
    "    Args:\n",
    "        kernel_memory_store (callable): A callable object that represents the kernel memory store where data will be upserted.\n",
    "        memory_store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory stores in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n += 1\n",
    "            # check if the item already exists in the memory store\n",
    "            # if the id doesn't exist, it throws an exception\n",
    "            try:\n",
    "                already_created = bool(\n",
    "                    await store.get(\n",
    "                        collection_name, item[\"id\"], with_embedding=True\n",
    "                    )\n",
    "                )\n",
    "            except Exception:\n",
    "                already_created = False\n",
    "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
    "            if not already_created:\n",
    "                await memory.save_information(\n",
    "                    collection=collection_name,\n",
    "                    id=item[\"id\"],\n",
    "                    # the embedding is generated from the text field\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"],\n",
    "                )\n",
    "                print(\n",
    "                    \"Generating embeddings and saving new item:\",\n",
    "                    n,\n",
    "                    \"/\",\n",
    "                    len(data),\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping item already exists:\", n, \"/\", len(data), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare Semantic Kernel, Generate embeddings for Azure Cosmos DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Skipping item already exists: 50 / 50\r"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "# Intialize the kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# Load the embeddings deployment name and initialize the text embedding with the required parameters, \n",
    "# Add the created embedding service to the semantic kernel instance.\n",
    "kernel.add_service(\n",
    "    AzureTextEmbedding(\n",
    "        service_id=\"text_embedding\",\n",
    "        deployment_name=openai.api_embeddings_deployment_name,\n",
    "        endpoint=openai.api_base,\n",
    "        api_key=openai.api_key,\n",
    "    )\n",
    ")\n",
    "\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store = await AzureCosmosDBMemoryStore.create(\n",
    "    cosmos_connstr=AZCOSMOS_CONNSTR,\n",
    "    cosmos_api=AZCOSMOS_API,\n",
    "    database_name=AZCOSMOS_DATABASE_NAME,\n",
    "    collection_name=AZCOSMOS_CONTAINER_NAME,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity,\n",
    ")\n",
    "\n",
    "# Add the created memory store to the semantic kernel instance.\n",
    "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
    "#kernel.import_plugin_from_object(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")\n",
    "\n",
    "#Call the helper function with the JSON data file to generate embeddings and create or update the database records.\n",
    "# If the records already exit it will skip it.\n",
    "# Records are identified by their ids. \n",
    "# **Note that you need to specify id, text, and description fields.The text field is what gets converted to embeddings.**\n",
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(memory, store, \"./data/dbm-saro.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: SARO Number: SARO-ROVI-24-0006778; Amount: 2,400,000.00; Approved Date: 09/03/2024 14:20:55;  Release Date: 09/03/2024 14:20:55; Department: 07 - Department of Agriculture; Agency: 021-National Irrigation Administration; Operating Unit: 070005 - Bicol; Purpose: Release of allotment for the construction of irrigation systems in Bicol.\n",
      "Relevance Score: 0.8803885961273783\n",
      "Full Record: {\"text\": \"SARO Number: SARO-ROVI-24-0006778; Amount: 2,400,000.00; Approved Date: 09/03/2024 14:20:55;  Release Date: 09/03/2024 14:20:55; Department: 07 - Department of Agriculture; Agency: 021-National Irrigation Administration; Operating Unit: 070005 - Bicol; Purpose: Release of allotment for the construction of irrigation systems in Bicol.\", \"description\": \"SARO-ROVI-24-0006778\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"Is there a SARO for irrigation systems in Bicol?\"\n",
    "result = await memory.search(collection_name, query_term)\n",
    "\n",
    "print(\n",
    "    f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"SARO Number: SARO-ROVI-24-0006771; Amount: 3,600,000.00; Approved Date: 08/27/2024 16:25:10;  Release Date: 08/27/2024 16:25:10; Department: 16 - Department of Transportation; Agency: 014-Land Transportation Office; Operating Unit: 160003 - Central Visayas; Purpose: Release of allotment for the improvement of land transportation services in Central Visayas.\", \"description\": \"SARO-ROVI-24-0006771\", \"additional_metadata\": null}, {\"text\": \"SARO Number: SARO-ROVI-24-0006801; Amount: 3,500,000.00; Approved Date: 09/26/2024 14:04:30;  Release Date: 09/26/2024 14:04:30; Department: 16 - Department of Transportation; Agency: 044-Philippine Ports Authority; Operating Unit: 160010 - Central Visayas; Purpose: Release of allotment for the construction of new port facilities in Central Visayas.\", \"description\": \"SARO-ROVI-24-0006801\", \"additional_metadata\": null}, {\"text\": \"SARO Number: SARO-ROVI-24-0006790; Amount: 4,400,000.00; Approved Date: 09/15/2024 15:24:55;  Release Date: 09/15/2024 15:24:55; Department: 12 - Department of Health; Agency: 033-National Children's Hospital; Operating Unit: 120006 - Central Visayas; Purpose: Release of allotment for the improvement of pediatric healthcare services in Central Visayas.\", \"description\": \"SARO-ROVI-24-0006790\", \"additional_metadata\": null}, {\"text\": \"SARO Number: SARO-ROVI-24-0006779; Amount: 1,700,000.00; Approved Date: 09/04/2024 08:45:20;  Release Date: 09/04/2024 08:45:20; Department: 16 - Department of Transportation; Agency: 022-Civil Aviation Authority of the Philippines; Operating Unit: 160005 - Eastern Visayas; Purpose: Release of allotment for the improvement of airport facilities in Eastern Visayas.\", \"description\": \"SARO-ROVI-24-0006779\", \"additional_metadata\": null}, {\"text\": \"SARO Number: SARO-ROVI-24-0006800; Amount: 1,600,000.00; Approved Date: 09/25/2024 09:39:05;  Release Date: 09/25/2024 09:39:05; Department: 07 - Department of Agriculture; Agency: 043-Bureau of Fisheries and Aquatic Resources; Operating Unit: 070010 - Northern Mindanao; Purpose: Release of allotment for the establishment of fish sanctuaries in Northern Mindanao.\", \"description\": \"SARO-ROVI-24-0006800\", \"additional_metadata\": null},\n"
     ]
    }
   ],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"How many SAROs are there for Central Visayas?\"\n",
    "result = await memory.search(collection_name, query_term, 5, 0.75, False)\n",
    "\n",
    "concatenated_result = \"\"\n",
    "\n",
    "for item in result:\n",
    "    #print(f\"Result is: {item.text}\")\n",
    "    #print(f\"Relevance Score: {item.relevance}\")\n",
    "    #print(f\"Full Record: {item.additional_metadata}\")\n",
    "    concatenated_result += item.additional_metadata + \", \"\n",
    "\n",
    "print(concatenated_result.strip())  # Use strip() to remove any trailing whitespace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
