{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Pattern\n",
    "In the previous video, we used two-agent conversation, which can be started by the initiate_chat method. Two-agent chat is a useful conversation pattern but AutoGen offers more. \n",
    "In this video, we will first dig a little bit more into the two-agent chat pattern and chat result, then we will show you several conversation patterns that involve more than two agents.\n",
    "\n",
    "Types:\n",
    "1. Two-agent chat: the simplest form of conversation pattern where two agents chat with each other.\n",
    "2. Sequential chat: a sequence of chats between two agents, chained together by a carryover mechanism, which brings the summary of the previous chat to the context of the next chat.\n",
    "3. Group Chat: a single chat involving more than two agents. An important question in group chat is: What agent should be next to speak? To support different scenarios, here are the different ways to organize agents in a group chat:\n",
    "    a. Support several strategies to select the next agent: round_robin, random, manual (human selection), and auto (Default, using an LLM to decide).\n",
    "    b. Provide a way to constrain the selection of the next speaker.\n",
    "    c. Pass in a function to customize the selection of the next speaker. With this feature, you can build a StateFlow model which allows a deterministic workflow among your agents.\n",
    "4. Nested Chat: package a workflow into a single agent for reuse in a larger workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "llm_config = [{\"model\": azure_deployment,\n",
    "               \"api_type\": \"azure\",\n",
    "               \"temperature\": 0.9,\n",
    "               \"api_key\": api_key,\n",
    "               \"base_url\": azure_endpoint,\n",
    "               \"api_version\": \"2024-02-15-preview\"}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chat\n",
    "\n",
    "In this pattern, the pair of agents first start a two-agent chat, then the summary of the conversation becomes a <b>carryover</b> for the next two-agent chat. The next chat passes the carryover to the carryover parameter of the context to generate its initial message.\n",
    "\n",
    "<b> Carryover accumulates as the conversation moves forward, so each subsequent chat starts with all the carryovers from previous chats.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "# The Number Agent always returns the same numbers.\n",
    "number_agent = ConversableAgent(\n",
    "    name=\"Number_Agent\",\n",
    "    system_message=\"You return me the numbers I give you, one number each line.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Adder Agent adds 1 to each number it receives.\n",
    "adder_agent = ConversableAgent(\n",
    "    name=\"Adder_Agent\",\n",
    "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Multiplier Agent multiplies each number it receives by 2.\n",
    "multiplier_agent = ConversableAgent(\n",
    "    name=\"Multiplier_Agent\",\n",
    "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Subtracter Agent subtracts 1 from each number it receives.\n",
    "subtracter_agent = ConversableAgent(\n",
    "    name=\"Subtracter_Agent\",\n",
    "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Divider Agent divides each number it receives by 2.\n",
    "divider_agent = ConversableAgent(\n",
    "    name=\"Divider_Agent\",\n",
    "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a sequence of two-agent chats.\n",
    "# Each element in the list is a dictionary that specifies the arguments\n",
    "# for the initiate_chat method.\n",
    "max_turns = 1\n",
    "chat_results = number_agent.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": adder_agent,\n",
    "            \"message\": \"14\",\n",
    "            \"max_turns\": max_turns,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": multiplier_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": max_turns,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": subtracter_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": max_turns,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": divider_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": max_turns,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First Chat Summary: \", chat_results[0].summary)\n",
    "print(\"Second Chat Summary: \", chat_results[1].summary)\n",
    "print(\"Third Chat Summary: \", chat_results[2].summary)\n",
    "print(\"Fourth Chat Summary: \", chat_results[3].summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Chat\n",
    "\n",
    "Group chat involves more than two agents. In group chat all agents contribute to a single conversation thread and share the same context. This is useful for tasks that require collaboration among multiple agents.\n",
    "\n",
    "A group chat is orchestrated by a special agent type GroupChatManager. In the first step of the group chat, the Group Chat Manager selects an agent to speak. Then, the selected agent speaks and the message is sent back to the Group Chat Manager, who broadcasts the message to all other agents in the group. This process repeats until the conversation stops.\n",
    "\n",
    "The Group Chat Manager can use several strategies to select the next agent. Currently, the following strategies are supported:\n",
    "\n",
    "1. round_robin: The Group Chat Manager selects agents in a round-robin fashion based on the order of the agents provided.\n",
    "2. random: The Group Chat Manager selects agents randomly.\n",
    "3. manual: The Group Chat Manager selects agents by asking for human input.\n",
    "4. auto: The default strategy, which selects agents using the Group Chat Managerâ€™s LLM.\n",
    "\n",
    "\n",
    "It can be hard to control if the number of participating agents is large. AutoGen provides a way to constrain the selection of the next speaker by using the allowed_or_disallowed_speaker_transitions argument of the GroupChat class.\n",
    "\n",
    "The allowed_or_disallowed_speaker_transitions argument is a dictionary that maps a given agent to a list of agents that can (or cannot) be selected to speak next. The speaker_transitions_type argument specifies whether the transitions are allowed or disallowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "# The Number Agent always returns the same numbers.\n",
    "number_agent = ConversableAgent(\n",
    "    name=\"Number_Agent\",\n",
    "    system_message=\"You return the number given to you.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg[\"content\"] or \"achieved\" in msg[\"content\"]\n",
    ")\n",
    "\n",
    "# The Adder Agent adds 1 to each number it receives.\n",
    "adder_agent = ConversableAgent(\n",
    "    name=\"Adder_Agent\",\n",
    "    system_message=\"You add 1 to number provided to you and return the number. You will not perform other computations other than that.\",\n",
    "    description = \"Add 1 to each input number.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Multiplier Agent multiplies each number it receives by 2.\n",
    "multiplier_agent = ConversableAgent(\n",
    "    name=\"Multiplier_Agent\",\n",
    "    system_message=\"You multiply number provided to you by 2 and return the number. You will not perform other computations other than that.\",\n",
    "    description = \"Multiply input number by 2.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Subtracter Agent subtracts 1 from each number it receives.\n",
    "subtracter_agent = ConversableAgent(\n",
    "    name=\"Subtracter_Agent\",\n",
    "    system_message=\"You subtract 1 from number provided to you and return the number. You will not perform other computations other than that.\",\n",
    "    description = \"Subtract 1 from input number.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Divider Agent divides each number it receives by 2.\n",
    "divider_agent = ConversableAgent(\n",
    "    name=\"Divider_Agent\",\n",
    "    system_message=\"You divide number provided to you by 2 and return the number. You will not perform other computations other than that.\",\n",
    "    description = \"Divide input number by 2.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "allowed_transitions = {\n",
    "    number_agent: [adder_agent, number_agent],\n",
    "    adder_agent: [multiplier_agent, number_agent],\n",
    "    subtracter_agent: [divider_agent, number_agent],\n",
    "    multiplier_agent: [subtracter_agent, number_agent],\n",
    "    divider_agent: [adder_agent, number_agent],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager\n",
    "\n",
    "group_chat = GroupChat(\n",
    "    agents=[adder_agent, multiplier_agent, subtracter_agent, divider_agent, number_agent],\n",
    "    messages=[],\n",
    "    max_round=50,#max iterations of the group chat\n",
    "    allowed_or_disallowed_speaker_transitions=allowed_transitions,\n",
    "    speaker_transitions_type=\"allowed\",\n",
    "    speaker_selection_method=\"auto\",\n",
    "    #send_introductions=True #Sometimes it is useful have each agent introduce themselves to other agents in the group chat.\n",
    ")\n",
    "\n",
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config={\"config_list\": llm_config},\n",
    ")\n",
    "\n",
    "# Number Agent to start a two-agent chat with the Group Chat Manager, which runs the group chat internally. \n",
    "# Group Chat Manager terminates the two-agent chat when the internal group chat is done. \n",
    "# Because the Number Agent is selected to speak by us, it counts as the first round of the group chat.\n",
    "chat_result = number_agent.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"My number is 3, use operations to turn this to 15. Terminate when 15 is achieved.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
