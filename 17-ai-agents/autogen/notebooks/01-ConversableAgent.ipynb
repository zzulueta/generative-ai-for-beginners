{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen-agentchat~=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "llm_config = [{\"model\": azure_deployment,\n",
    "               \"api_type\": \"azure\",\n",
    "               \"temperature\": 0.9,\n",
    "               \"api_key\": api_key,\n",
    "               \"base_url\": azure_endpoint,\n",
    "               \"api_version\": \"2024-02-15-preview\"}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an AutoGen ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke about Autogen.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out results:\n",
    "1. Chat history\n",
    "2. Cost\n",
    "3. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaut summary is the last message of the conversation\n",
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters in initiate_chat\n",
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. Give me a joke about Autogen.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Control Termination with AutoGen? \n",
    "Currently there are two broad mechanism to control the termination of conversations between agents:\n",
    "1. Specify parameters in initiate_chat: When initiating a chat, you can define parameters that determine when the conversation should end.\n",
    "2. Configure an agent to trigger termination: When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions. Currently, there are two parameters you can configure:\n",
    "    <br> 2.1.  max_consecutive_auto_reply: This condition triggers termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the max_consecutive_auto_reply argument of the ConversableAgent class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention. We will describe this in more detail in the next chapter.\n",
    "    <br> 2.2. is_termination_msg: This condition can trigger termination if the received message satisfies a particular condition, e.g., it contains the word “TERMINATE”. You can customize this condition using the is_terminate_msg argument in the constructor of the ConversableAgent class.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "#max_consecutive_auto_reply\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=2,\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# is_termination_msg sample\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go' or 'Goodbye'.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Input Modes\n",
    "The mode is specified through the human_input_mode argument of the ConversableAgent. The modes are:\n",
    "1. NEVER: human input is never requested.\n",
    "2. TERMINATE (default): human input is only requested when a termination condition is met. Note that in this mode if the human chooses to intercept and reply, the conversation continues and the counter used by max_consecutive_auto_reply is reset.\n",
    "3. Human input is always requested and the human can choose to skip and trigger an auto-reply, intercept and provide feedback, or terminate the conversation. Note that in this mode termination based on max_consecutive_auto_reply is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Human input mode TERMINATE\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"TERMINATE\", #this can be removed as this is the default setting if none is provided\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Human input mode ALWAYS\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
