{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen-agentchat~=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key=os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "llm_config = [{\"model\": azure_deployment,\n",
    "               \"api_type\": \"azure\",\n",
    "               \"temperature\": 0.9,\n",
    "               \"api_key\": api_key,\n",
    "               \"base_url\": azure_endpoint,\n",
    "               \"api_version\": \"2024-02-15-preview\"}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an AutoGen ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[{\"content\": \"Tell me a joke about Autogen.\", \"role\": \"user\"}]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation\n",
    "\n",
    "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"Start the next joke from the punchline of the previous joke.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\",\n",
    "    max_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print out results:\n",
    "### a. Chat history\n",
    "### b. Cost\n",
    "### c. Summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a better summary of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters in initiate_chat\n",
    "chat_result = joe.initiate_chat(\n",
    "    cathy, \n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. Give me a joke about Autogen.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Control Termination with AutoGen? \n",
    "## Currently there are two broad mechanism to control the termination of conversations between agents:\n",
    "\n",
    "### a. Specify parameters in initiate_chat: When initiating a chat, you can define parameters that determine when the conversation should end.\n",
    "### b. Configure an agent to trigger termination: When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions. Currently, there are two parameters you can configure:\n",
    "#### b.1.  max_consecutive_auto_reply: This condition triggers termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the max_consecutive_auto_reply argument of the ConversableAgent class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention. We will describe this in more detail in the next chapter.\n",
    "#### b.2. is_termination_msg: This condition can trigger termination if the received message satisfies a particular condition, e.g., it contains the word “TERMINATE”. You can customize this condition using the is_terminate_msg argument in the constructor of the ConversableAgent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "#max_consecutive_auto_reply\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=2,\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# is_termination_msg sample\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go' or 'Goodbye'.\",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Input Modes\n",
    "## The mode is specified through the human_input_mode argument of the ConversableAgent. The modes are:\n",
    "### 1. NEVER: human input is never requested.\n",
    "### 2. TERMINATE (default): human input is only requested when a termination condition is met. Note that in this mode if the human chooses to intercept and reply, the conversation continues and the counter used by max_consecutive_auto_reply is reset.\n",
    "### 3. Human input is always requested and the human can choose to skip and trigger an auto-reply, intercept and provide feedback, or terminate the conversation. Note that in this mode termination based on max_consecutive_auto_reply is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Great to have you here. So, I went to the doctor the other day. He told me I had to stop playing the guitar. And I was like, \"Why, doc?\" He said, \"Because you're terrible at it!\" \n",
      "\n",
      "Your turn, Joe. Why don't you hit me with a joke?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Hey Cathy! That was a good one. Alright, here’s mine:\n",
      "\n",
      "Why don’t scientists trust atoms anymore?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Nice one, Joe! I love a good science joke. Alright, here’s another one for you:\n",
      "\n",
      "Why did the scarecrow win an award?\n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Good one, Cathy! Alright, here’s another for you:\n",
      "\n",
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that's a classic, Joe! Alright, let me try to keep up with you:\n",
      "\n",
      "Why did the coffee file a police report?\n",
      "\n",
      "It got mugged!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Oh, that's a good one, Cathy! Alright, here’s one more for you:\n",
      "\n",
      "Why did the math book look sad?\n",
      "\n",
      "Because it had too many problems!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, math problems really do get you down! Alright, here’s one more from me:\n",
      "\n",
      "Why don't eggs tell jokes?\n",
      "\n",
      "Because they might crack up!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a cracking good one, Cathy! Alright, here’s my last one for you:\n",
      "\n",
      "Why don’t oysters donate to charity?\n",
      "\n",
      "Because they’re shellfish!\n",
      "\n",
      "Alright, I gotta go. It’s been a blast joking around with you! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hahaha, that’s a fin-tastic one to finish on, Joe! Thanks for all the laughs. It’s been a shell of a time! Take care and see you next time! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "make another round of jokes. Topic is about Autogen\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Alright Joe, let’s dive into the world of Autogen jokes!\n",
      "\n",
      "Why did the AI go to school?\n",
      "\n",
      "Because it wanted to improve its algorithm-ic!\n",
      "\n",
      "Your turn, Joe! Hit me with an Autogen joke!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Alright, Cathy, here’s one for you:\n",
      "\n",
      "Why did the AI break up with its robot girlfriend?\n",
      "\n",
      "She found out he was just stringing her along!\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, that’s a clever one, Joe! Alright, here’s another:\n",
      "\n",
      "Why was the AI always calm?\n",
      "\n",
      "Because it had a lot of “neural networks” to lean on!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Great one, Cathy! Here's another for you:\n",
      "\n",
      "Why did the AI apply for a job?\n",
      "\n",
      "Because it heard it could finally get some real \"data entry\"!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, I love it, Joe! Here's another one from me:\n",
      "\n",
      "Why did the AI get promoted?\n",
      "\n",
      "Because it was outstanding in “machine learning”!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That’s a good one, Cathy! Here’s one more from me:\n",
      "\n",
      "Why did the AI start a band?\n",
      "\n",
      "Because it had great “neural notes”!\n",
      "\n",
      "Alright, I gotta go. It’s been an amazing time sharing these jokes with you, Cathy! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/generative-ai-for-beginners/.venv/lib/python3.12/site-packages/autogen/agentchat/conversable_agent.py:1461: UserWarning: Extracted_response from ChatCompletion(id='chatcmpl-ASDhPsqBOMUQjv2FSnP2hibe8a6u5', choices=[Choice(finish_reason='content_filter', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1731289207, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_67802d9a6d', usage=CompletionUsage(completion_tokens=38, prompt_tokens=742, total_tokens=780), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {}}], cost=0.00428, message_retrieval_function=<bound method OpenAIClient.message_retrieval of <autogen.oai.client.OpenAIClient object at 0x75326a889850>>, config_id=0, pass_filter=True) is None.\n",
      "  warnings.warn(f\"Extracted_response from {response} is None.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, you've been awesome! But I gotta go. Catch you next time! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "You've been fantastic too, Joe! Thanks for all the laughs. Catch you next time! Goodbye!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Human input mode TERMINATE\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Joe and Cathy exchanged a series of jokes, starting with general jokes and '\n",
      " \"then focusing on Autogen-themed humor. They enjoyed each other's company, \"\n",
      " 'shared laughs, and parted on good terms, expressing appreciation for the fun '\n",
      " 'interaction.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Hey Joe! Great to have you here. So, I went to the doctor the other day. He told me I had to stop playing the guitar. And I was like, \"Why, doc?\" He said, \"Because you're terrible at it!\" \n",
      "\n",
      "Your turn, Joe. Why don't you hit me with a joke?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Make a joke regarding Autogen\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure thing, Joe! So, you know Autogen, right? That software that writes text automatically? I heard it tried to write a love letter the other day...\n",
      "\n",
      "It started with, \"Dear [Insert Beloved's Name],\"\n",
      "\n",
      "Turns out, even AI needs some help in the romance department!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "continue\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Alright, Joe, let's keep it going! So Autogen tries to write poetry next. It came up with:\n",
      "\n",
      "\"Roses are #FF0000,\n",
      "Violets are #0000FF,\n",
      "Sugar is C12H22O11,\n",
      "And so are you!\"\n",
      "\n",
      "I guess chemistry isn't the best way to win hearts, huh? \n",
      "\n",
      "What about you, Joe? Got any tech jokes up your sleeve?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "make a joke about OpenAI Assistants\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, I've got one for you, Joe! You know these OpenAI Assistants, right? They're like your best friends who never fail to have the right answer. \n",
      "\n",
      "But you ever try to tell them a secret? \n",
      "\n",
      "They'd be like, \"Sorry, my knowledge is shared across instances, confidentiality not guaranteed.\"\n",
      "\n",
      "Not exactly the best choice for a therapist, huh?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "how about Semantic Kernel\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Oh, Semantic Kernel, that's a good one, Joe! You know, they say Semantic Kernel helps with understanding the meaning behind words, right?\n",
      "\n",
      "I tried explaining my feelings to it, and it responded with, \"Processing... Your emotional complexity exceeds current parameters. Please consult a human.\"\n",
      "\n",
      "Looks like even the Semantic Kernel can't handle my emotional baggage!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Goodbye\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Alright, Joe! It's been a blast cracking jokes with you. Remember, if you ever need a laugh, you know where to find me. Take care and keep smiling!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cathy = ConversableAgent(\n",
    "    name=\"cathy\",\n",
    "    system_message=\n",
    "    \"Your name is Cathy and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# Human input mode ALWAYS\n",
    "joe = ConversableAgent(\n",
    "    name=\"joe\",\n",
    "    system_message=\n",
    "    \"Your name is Joe and you are a stand-up comedian. \",\n",
    "    llm_config={\"config_list\": llm_config},\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "chat_result = joe.initiate_chat(\n",
    "    recipient=cathy,\n",
    "    message=\"I'm Joe. Cathy, let's keep the jokes rolling. We end the conversation when we feel like it.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    "    summary_prompt=\"Summarize the conversation\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
